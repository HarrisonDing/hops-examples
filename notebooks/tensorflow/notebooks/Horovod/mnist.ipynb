{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist distributed training using Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> <h3>To run the code in this notebook, go to [launch_horovod.ipynb](launch_horovod.ipynb). Running this notebook will not enable Horovod and results in errors!</h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading up [basics about Hops Notebook and local training models on Hops](../TensorFlow/cifar10_on_hops.ipynb) it's time to scale out our training. We already discussed [multi-gpu training with TensorFlow](../TensorFlow/multigpu/Multi-gpu_training_cifar.ipynb) but the key difference here is using [Horovod](https://github.com/uber/horovod) library to parallelize the training. The reason to do this is great scaling capabilities this library has in compare to traditional methods due to using MPI and Ring allreduce concepts for parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flatten and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd\n",
    "layers = tf.contrib.layers\n",
    "learn = tf.contrib.learn\n",
    "from hops import tensorboard\n",
    "from hops import hdfs\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(feature, target, mode):\n",
    "    \"\"\"2-layer convolution model.\"\"\"\n",
    "    # Convert the target to a one-hot tensor of shape (batch_size, 10) and\n",
    "    # with a on-value of 1 for each one-hot vector of length 10.\n",
    "    target = tf.one_hot(tf.cast(target, tf.int32), 10, 1, 0)\n",
    "\n",
    "    # Reshape feature to 4d tensor with 2nd and 3rd dimensions being\n",
    "    # image width and height final dimension being the number of color channels.\n",
    "    feature = tf.reshape(feature, [-1, 28, 28, 1])\n",
    "    tf.summary.image(\"image\", feature)\n",
    "\n",
    "    # First conv layer will compute 32 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer1'):\n",
    "        h_conv1 = layers.conv2d(\n",
    "            feature, 32, kernel_size=[5, 5], activation_fn=tf.nn.relu)\n",
    "        h_pool1 = tf.nn.max_pool(\n",
    "            h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second conv layer will compute 64 features for each 5x5 patch.\n",
    "    with tf.variable_scope('conv_layer2'):\n",
    "        h_conv2 = layers.conv2d(\n",
    "            h_pool1, 64, kernel_size=[5, 5], activation_fn=tf.nn.relu)\n",
    "        h_pool2 = tf.nn.max_pool(\n",
    "            h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        # reshape tensor into a batch of vectors\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Densely connected layer with 1024 neurons.\n",
    "    h_fc1 = layers.dropout(\n",
    "        layers.fully_connected(\n",
    "            h_pool2_flat, 1024, activation_fn=tf.nn.relu),\n",
    "        keep_prob=0.5,## Building the model\n",
    "        is_training=mode == tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "    # Compute logits (1 per class) and compute loss.\n",
    "    logits = layers.fully_connected(h_fc1, 10, activation_fn=None)\n",
    "    loss = tf.losses.softmax_cross_entropy(target, logits)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    return tf.argmax(logits, 1), loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Horovod\n",
    "\n",
    "Until now everything was quite standard in Deep learning techniques and Hops concepts. For running our code using Horovod however, we need to modify just few lines of our code. This few lines will enable us to scale our model potentially on hundreds of GPUs very well, providing optimal data input pipeline and fast GPUs connection between each other. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Step to scale out with Horovod:\n",
    "\n",
    "#### 1. Initilization using `hvd.init()`\n",
    "#### 2. Making our optimizer Horovod-friendly:\n",
    "```python\n",
    "opt = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "# Wrap with Distributed Optimizer\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "\n",
    "####  3. Mind the rank:\n",
    "As now we have potential tens or hundreds of GPUs running the same code, we need to take care of checkpointing and writing summaries. More specifically, we need to do this actions on only one machine. For this we need to check the rank of GPU before each of these actions. In broadcasting step, we will use this concept.\n",
    "\n",
    "####  4. Providing `Config`: \n",
    "Pin GPU to be used to process local rank (one GPU per process)\n",
    "\n",
    "```python\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "```\n",
    "####  5. Broadcasting: \n",
    "Broadcast initial variable states from rank 0 to all other processes. This is necessary to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.\n",
    "\n",
    "```python\n",
    "if hvd.local_rank()==0:\n",
    "    hooks = [hvd.BroadcastGlobalVariablesHook(0),\n",
    "         tf.train.StopAtStepHook(last_step=5000),\n",
    "         tf.train.LoggingTensorHook(tensors={'step': global_step, 'loss': loss},\n",
    "                                    every_n_iter=10),\n",
    "         tf.train.SummarySaverHook(save_steps=10,\n",
    "                                   output_dir=tensorboard.logdir(),\n",
    "                                   summary_op=tf.summary.merge_all()),\n",
    "        tf.train.CheckpointSaverHook(checkpoint_dir=tensorboard.logdir(), save_steps=50)\n",
    "         ]\n",
    "else:\n",
    "    hooks = [hvd.BroadcastGlobalVariablesHook(0),\n",
    "         tf.train.StopAtStepHook(last_step=5000)\n",
    "         ]\n",
    "```\n",
    "\n",
    "#### 6. Provide `hooks` and `config` to the Session:\n",
    "Don't forget to run broadcasting operation which we defined earlier after initilization of variable:\n",
    "\n",
    "```python\n",
    "with tf.train.SingularMonitoredSession(hooks=hooks, config=config) as mon_sess:\n",
    "```\n",
    "\n",
    "Since we are using `SingularMonitoredSession` the initilization of variables and broadcasting is handled by implicitly and the broadcasting operator is initilized inside the `hooks` list.\n",
    "#### 7. Launch it:\n",
    "\n",
    "Congrats, we finished adapting our code to use Horovod, but for actually start training, we need to have another notebook. Refer to [launch_horovod.ipynb](launch_horovod.ipynb) notebook for further instruction on how to run and monitor your training process. \n",
    "\n",
    "<font color='red'> <h4>To launch this notebook, go to [launch_horovod.ipynb](launch_horovod.ipynb). Running this notebook will not enable Horovod and results in errors!</h4></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # Initialize Horovod.\n",
    "    hvd.init()\n",
    "\n",
    "    # Download and load MNIST dataset.\n",
    "    mnist = learn.datasets.mnist.read_data_sets('MNIST-data-%d' % hvd.rank())\n",
    "\n",
    "    # Build model...\n",
    "    with tf.name_scope('input'):\n",
    "        image = tf.placeholder(tf.float32, [None, 784], name='image')\n",
    "        label = tf.placeholder(tf.float32, [None], name='label')\n",
    "    predict, loss = conv_model(image, label, tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "    opt = tf.train.RMSPropOptimizer(0.01)\n",
    "\n",
    "    # Add Horovod Distributed Optimizer.\n",
    "    opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "    train_op = opt.minimize(loss, global_step=global_step)\n",
    "\n",
    "    print(tensorboard.logdir())\n",
    "\n",
    "    # BroadcastGlobalVariablesHook broadcasts variables from rank 0 to all other\n",
    "    # processes during initialization.\n",
    "    if hvd.local_rank()==0:\n",
    "        hooks = [hvd.BroadcastGlobalVariablesHook(0),\n",
    "             tf.train.StopAtStepHook(last_step=5000),\n",
    "             tf.train.LoggingTensorHook(tensors={'step': global_step, 'loss': loss},\n",
    "                                        every_n_iter=10),\n",
    "             tf.train.SummarySaverHook(save_steps=10,\n",
    "                                       output_dir=tensorboard.logdir(),\n",
    "                                       summary_op=tf.summary.merge_all()),\n",
    "            tf.train.CheckpointSaverHook(checkpoint_dir=tensorboard.logdir(), save_steps=50)\n",
    "             ]\n",
    "    else:\n",
    "        hooks = [hvd.BroadcastGlobalVariablesHook(0),\n",
    "             tf.train.StopAtStepHook(last_step=5000)\n",
    "             ]\n",
    "\n",
    "    # Pin GPU to be used to process local rank (one GPU per process)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "\n",
    "    # The MonitoredTrainingSession takes care of session initialization,\n",
    "    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n",
    "    # or an error occurs.\n",
    "    with tf.train.SingularMonitoredSession(hooks=hooks, config=config) as mon_sess:\n",
    "        while not mon_sess.should_stop():\n",
    "            # Run a training step synchronously.\n",
    "            image_, label_ = mnist.train.next_batch(100)\n",
    "            mon_sess.run(train_op, feed_dict={image: image_, label: label_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't forget:\n",
    "To call the main function if you wrapped your model logic in the `main()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
